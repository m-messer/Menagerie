{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import hashlib\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Assignment Processor - Anonymization and Deduplication\n",
    "## Deduplication\n",
    "### Find duplicates in reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = \"data/reports\"\n",
    "NAME_REGEX = r'[0-9]+\\s-\\s[A-Za-z\\s\\-]+'\n",
    "\n",
    "def generate_hashes(start_path):\n",
    "    hashes = {}\n",
    "\n",
    "    for root, _, files in os.walk(start_path):\n",
    "        for file in files:\n",
    "            if not file.endswith((\".pdf\", \".docx\")):\n",
    "                continue\n",
    "\n",
    "            with open(os.path.join(root, file), \"rb\") as f:\n",
    "                digest = hashlib.file_digest(f, \"sha256\")\n",
    "\n",
    "            dhash = digest.hexdigest()\n",
    "\n",
    "            # Potentially convert tuple to DAO\n",
    "            path = os.path.join(root, file)\n",
    "            year = root[len(root) - 5:].replace('_', '~')\n",
    "            student_name = re.findall(NAME_REGEX, file)[0].split(' - ')[1].strip().replace('-', ' ')\n",
    "            data = (path, year, student_name)\n",
    "\n",
    "            if dhash in hashes.keys():\n",
    "                hashes[dhash].append(data)\n",
    "            else:\n",
    "                hashes[dhash] = [data]\n",
    "\n",
    "    return hashes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_hashes(RAW_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Generate summary stats on duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(hashes):\n",
    "    print(\"Number of submission: \", sum([len(p) for p in hashes.values()]))\n",
    "    print(\"Number of unique solutions:\", len(hashes))\n",
    "    print(\"Number of duplicates: \", sum([len(p) for p in hashes.values()]) - len(hashes))\n",
    "    print(\"Max number of duplicates on a specific solution\", max([len(p) for p in hashes.values()]))\n",
    "\n",
    "stats(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Find duplicate paths in raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = \"data/raw\"\n",
    "DATE_REGEX = r'[0-9]+~[0-9]+'\n",
    "\n",
    "path_map = {}\n",
    "\n",
    "for root, _, files in os.walk(RAW_PATH):\n",
    "    for file in files:\n",
    "        if not file.endswith((\".jar\", \".zip\")):\n",
    "            continue\n",
    "\n",
    "        regex_lst = re.findall(DATE_REGEX, root)\n",
    "\n",
    "        if len(regex_lst) == 1:\n",
    "            date = regex_lst[0]\n",
    "        else:\n",
    "            date = \"21~22\"\n",
    "\n",
    "        if date not in path_map.keys():\n",
    "            path_map[date] = {}\n",
    "\n",
    "        path_split = root.split('/')\n",
    "\n",
    "        if len(path_split) < 4:\n",
    "            continue\n",
    "\n",
    "        student_name = path_split[3].split('_')[0].replace('-', ' ')\n",
    "\n",
    "        path_map[date][student_name] = os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Remove duplicates, moved to proc and rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_PATH = \"data/proc\"\n",
    "\n",
    "missing_submissions = []\n",
    "\n",
    "if not os.path.exists(PROCESSED_PATH):\n",
    "    os.mkdir(PROCESSED_PATH)\n",
    "\n",
    "for counter, duplicate in enumerate(results.values()):\n",
    "    year = duplicate[0][1]\n",
    "    student_name = duplicate[0][2]\n",
    "\n",
    "    if student_name not in path_map[year]:\n",
    "        missing_submissions.append((year, student_name))\n",
    "        continue\n",
    "    path = path_map[duplicate[0][1]][duplicate[0][2]]\n",
    "\n",
    "\n",
    "    if not os.path.exists(os.path.join(PROCESSED_PATH, year)):\n",
    "        os.mkdir(os.path.join(PROCESSED_PATH, year))\n",
    "\n",
    "    file_name = year + \"_Submission_\" + str(counter)\n",
    "\n",
    "    proc_path = os.path.join(PROCESSED_PATH, year, file_name)\n",
    "\n",
    "    if not os.path.exists(proc_path):\n",
    "        os.mkdir(proc_path)\n",
    "\n",
    "        file_ext = path.split(\".\")\n",
    "\n",
    "        if len(file_ext) == 1:\n",
    "            ext = \".jar\"\n",
    "        else:\n",
    "            ext = \".\" + file_ext[len(file_ext) - 1]\n",
    "\n",
    "        new_path = file_name + ext\n",
    "\n",
    "        shutil.copyfile(path, os.path.join(proc_path, new_path))\n",
    "\n",
    "# Not found in automated processing, due to differences in names, can be manually extracted\n",
    "len(missing_submissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## File Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_files():\n",
    "    for root, _, files in os.walk(PROCESSED_PATH):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jar\") or file.endswith(\".zip\"):\n",
    "                path = os.path.join(root, file).replace(\" \", '\\ ')\n",
    "\n",
    "                try:\n",
    "                    os.system('unzip ' + path + \" -d ./\" + root.replace(\" \", \"\\ \") + \">/dev/null 2>&1\")\n",
    "                    os.remove(path)\n",
    "                except FileNotFoundError:\n",
    "                    print(\"Failed to unzip: \", path)\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_files() # Run a second time to extract any jar files that were zipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Remove unnecessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, subdirs, files in os.walk(PROCESSED_PATH):\n",
    "\n",
    "    for subdir in subdirs:\n",
    "        if subdir.startswith((\".\", \"_\")) or subdir == \"doc\" or subdir == 'META-INF' or subdir == 'out':\n",
    "            shutil.rmtree(os.path.join(root, subdir))\n",
    "\n",
    "    for file in files:\n",
    "        if file.lower().endswith((\".class\", \".ctxt\", \"~\", \".\", \".pdf\")):\n",
    "            os.remove(os.path.abspath(os.path.join(\"./\", root, file)))\n",
    "\n",
    "        if file.lower().endswith((\".zip\", \".jar\")) and not 'lib' in root:\n",
    "            os.remove(os.path.abspath(os.path.join(\"./\", root, file)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Anonymisation\n",
    "### Remove @author lines from all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTHOR_TAG_REGEX = '\\s*\\*\\s*@author.+'\n",
    "\n",
    "for root, _, files in os.walk(PROCESSED_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(\".java\"):\n",
    "            with open(os.path.join(root, file), \"r\", encoding=\"ISO-8859-1\") as f:\n",
    "                source_code = f.read()\n",
    "\n",
    "            source_code = re.sub(AUTHOR_TAG_REGEX, \"\", source_code)\n",
    "\n",
    "            with open(os.path.join(root, file), \"w\", encoding='utf-8') as f:\n",
    "                f.write(source_code)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
