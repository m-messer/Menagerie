{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Example Analysis of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_df = pd.read_pickle('../data/analysis_df.pickle')\n",
    "submissions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_df = pd.read_pickle('../data/template_df.pickle')\n",
    "template_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Number of classes\n",
    "#### Split categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_class_regex = '.*public class.*\\n?{'\n",
    "private_class_regex = '.*private class.*\\n?{'\n",
    "protected_class_regex = '.*protected class.*\\n?{'\n",
    "class_regex = '^class.*\\n?{'\n",
    "abstract_class_regex = '.*abstract class.*\\n?{'\n",
    "enum_regex = '.*enum.*\\n?{'\n",
    "interface_regex = '.*interface.*\\n?{'\n",
    "\n",
    "def process_classes(df):\n",
    "    proc_df = df.copy()\n",
    "\n",
    "    proc_df['no_public_classes'] = proc_df.src.apply(lambda src: len(re.findall(public_class_regex, src)))\n",
    "    proc_df['no_protected_classes'] = proc_df.src.apply(lambda src: len(re.findall(protected_class_regex, src)))\n",
    "    proc_df['no_private_classes'] = proc_df.src.apply(lambda src: len(re.findall(private_class_regex, src)))\n",
    "    proc_df['no_package_private_classes'] = proc_df.src.apply(lambda src: len(re.findall(class_regex, src)))\n",
    "    proc_df['no_abstract_classes'] = proc_df.src.apply(lambda src: len(re.findall(abstract_class_regex, src)))\n",
    "    proc_df['no_enums'] = proc_df.src.apply(lambda src: len(re.findall(enum_regex, src)))\n",
    "    proc_df['no_interfaces'] = proc_df.src.apply(lambda src: len(re.findall(interface_regex, src)))\n",
    "\n",
    "    proc_df['total'] = proc_df[['no_public_classes', 'no_protected_classes', 'no_private_classes', 'no_package_private_classes', 'no_abstract_classes', 'no_enums', 'no_interfaces']].sum(axis=1)\n",
    "\n",
    "    proc_df = proc_df.drop(['file_name', 'src'], axis=1)\n",
    "\n",
    "    return proc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_stack_classes(df):\n",
    "    grouped = df.groupby('dir').sum()\n",
    "\n",
    "    grouped = grouped.loc[:, (grouped != 0).any(axis=0)]\n",
    "    stacked = grouped.stack().reset_index().drop('dir', axis=1)\n",
    "    stacked.columns = ['class_type', 'class_count']\n",
    "\n",
    "    return stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_classes = process_classes(submissions_df)\n",
    "template_classes = process_classes(template_df)\n",
    "\n",
    "stacked_sub_classes =  group_stack_classes(sub_classes)\n",
    "stacked_template_classes =  group_stack_classes(template_classes)\n",
    "\n",
    "stacked_sub_classes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_template_classes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_sub_classes = stacked_sub_classes[stacked_sub_classes['class_type'] != 'total'].copy()\n",
    "\n",
    "stacked_sub_classes['source'] = 'submissions'\n",
    "stacked_template_classes['source'] = 'template'\n",
    "\n",
    "stacked_sub_classes['class_type'] = stacked_sub_classes['class_type'].apply(lambda class_type: \" \".join(class_type.split('_')[1:]).title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_template_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(stacked_sub_classes, x='class_count', y='class_type')\n",
    "ax.set(xlabel='Total Classes', ylabel='Class Type')\n",
    "\n",
    "# Manually done using the results from the cell above\n",
    "ax.vlines(9, -0.5, 0.5, color='red')\n",
    "ax.vlines(1, 3.5, 4.5, color='red')\n",
    "\n",
    "plt.savefig('plots/classes_sep.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Total classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_classes_total = sub_classes[['dir', 'total']].copy()\n",
    "template_classes_total = template_classes[['dir', 'total']].copy()\n",
    "\n",
    "sub_classes_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_classes_total['source'] = 'submissions'\n",
    "template_classes_total['source'] = 'template'\n",
    "\n",
    "classes_total = pd.concat([sub_classes_total, template_classes_total])\n",
    "\n",
    "temp_df = classes_total.groupby(['source', 'dir']).sum().reset_index()\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.boxplot(temp_df[temp_df['source'] == 'submissions'], x='total')\n",
    "ax.axvline(temp_df[temp_df['source'] == 'template'].iloc[0].total, color='red')\n",
    "ax.set(xlabel='Total Classes')\n",
    "\n",
    "plt.savefig('plots/classes_total.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### LOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc = df.copy()\n",
    "df_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_regex = '(\\/\\*\\*|\\*|\\/\\/)'\n",
    "sloc_regex = ';|(\\n?\\s*{)|}'\n",
    "\n",
    "\n",
    "df_loc['raw_lines'] = df.src.apply(lambda src: len(src.split('\\n')))\n",
    "# These do not sum to raw lines, as I count statement \\n { == 1 line not two\n",
    "df_loc['comment_lines'] = df.src.apply(lambda src: len(re.findall(comment_regex, src)))\n",
    "# Physical SLOC\n",
    "df_loc['sloc'] = df.src.apply(lambda src: len(re.findall(sloc_regex, src)))\n",
    "df_loc['whitespace'] = df.src.apply(lambda src: len([line for line in src.split('\\n') if len(line.strip()) == 0]) - 1)\n",
    "df_loc['whitespace'] = df_loc.whitespace.apply(lambda count: 0 if count < 0 else count)\n",
    "\n",
    "df_loc = df_loc.drop(['src'], axis=1)\n",
    "\n",
    "df_loc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Project Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_loc[['dir', 'raw_lines', 'comment_lines', 'sloc', 'whitespace']].groupby('dir').sum()\n",
    "\n",
    "grouped = grouped.loc[:, (grouped != 0).any(axis=0)]\n",
    "stacked = grouped.stack().reset_index().drop('dir', axis=1)\n",
    "stacked.columns = ['count_type', 'count']\n",
    "stacked.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(stacked, y='count_type', x='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### File Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = df_loc[['raw_lines', 'comment_lines', 'sloc', 'whitespace']].stack().reset_index().drop('level_0', axis=1)\n",
    "stacked.columns = ['count_type', 'count']\n",
    "stacked.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(stacked, y='count_type', x='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_regex = 'for\\s*\\([^;]*;[^;]*;.*\\)\\s*{'\n",
    "for_each_regex = 'for\\s*\\([^:]*:[^;]*\\)\\s*\\{'\n",
    "while_regex = 'while\\s*\\(.*\\)\\s*\\n?\\{'\n",
    "do_while_regex = 'do\\s*{[^}]*}\\s*while\\s*\\(.*\\);'\n",
    "\n",
    "df_iter['for'] = df.src.apply(lambda src: len(re.findall(for_regex, src)))\n",
    "df_iter['for_each'] = df.src.apply(lambda src: len(re.findall(for_each_regex, src)))\n",
    "df_iter['while'] = df.src.apply(lambda src: len(re.findall(while_regex, src)))\n",
    "df_iter['do_while'] = df.src.apply(lambda src: len(re.findall(do_while_regex, src)))\n",
    "\n",
    "df_iter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### File level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = df_iter[['for', 'for_each', 'while', 'do_while']].stack().reset_index().drop('level_0', axis=1)\n",
    "stacked.columns = ['count_type', 'count']\n",
    "stacked.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(stacked, y='count_type', x='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Project Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df_iter[['dir', 'for', 'for_each', 'while', 'do_while']].groupby('dir').sum()\n",
    "\n",
    "grouped = grouped.loc[:, (grouped != 0).any(axis=0)]\n",
    "stacked = grouped.stack().reset_index().drop('dir', axis=1)\n",
    "stacked.columns = ['count_type', 'count']\n",
    "stacked.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(stacked, y='count_type', x='count')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
